{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DACS Elevator Radio Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all relied libraries\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "# Initialize\n",
    "from data.base import store_lyrics, read_cleaned_data, evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from billboard top 100 不要重新运行\n",
    "If this year's data is stored then it won't grab again. You can directly use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal input year. Setting year to be the current.\n",
      "Searching for \"Heat Waves\" by Glass Animals...\n",
      "Done.\n",
      "Searching for \"As It Was\" by Harry Styles...\n",
      "Done.\n",
      "Searching for \"Stay\" by The Kid LAROI & Justin Bieber...\n",
      "Done.\n",
      "Searching for \"Easy On Me\" by Adele...\n",
      "Done.\n",
      "Searching for \"Shivers\" by Ed Sheeran...\n",
      "Done.\n",
      "Searching for \"First Class\" by Jack Harlow...\n",
      "Done.\n",
      "Searching for \"Big Energy\" by Latto...\n",
      "Done.\n",
      "Searching for \"Ghost\" by Justin Bieber...\n",
      "Done.\n",
      "Searching for \"Super Gremlin\" by Kodak Black...\n",
      "Done.\n",
      "Searching for \"Cold Heart (PNAU Remix)\" by Elton John & Dua Lipa...\n",
      "Done.\n",
      "Searching for \"Wait For U\" by Future Featuring Drake & Tems...\n",
      "Done.\n",
      "Searching for \"About Damn Time\" by Lizzo...\n",
      "Done.\n",
      "Searching for \"Bad Habits\" by Ed Sheeran...\n",
      "Done.\n",
      "Searching for \"Thats What I Want\" by Lil Nas X...\n",
      "Done.\n",
      "Searching for \"Enemy\" by Imagine Dragons X JID...\n",
      "Done.\n",
      "Searching for \"Industry Baby\" by Lil Nas X & Jack Harlow...\n",
      "Done.\n",
      "Searching for \"abcdefu\" by GAYLE...\n",
      "Done.\n",
      "Searching for \"Need To Know\" by Doja Cat...\n",
      "Done.\n",
      "Searching for \"Wasted On You\" by Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"Me Porto Bonito\" by Bad Bunny & Chencho Corleone...\n",
      "Done.\n",
      "Searching for \"Woman\" by Doja Cat...\n",
      "Done.\n",
      "Searching for \"Titi Me Pregunto\" by Bad Bunny...\n",
      "Done.\n",
      "Searching for \"Running Up That Hill (A Deal With God)\" by Kate Bush...\n",
      "Done.\n",
      "Searching for \"We Don't Talk About Bruno\" by Carolina Gaitan, Mauro Castillo, Adassa, Rhenzy Feliz, Diane Guerrero, Stephanie Beatriz & Encanto Cast...\n",
      "Done.\n",
      "Searching for \"Late Night Talking\" by Harry Styles...\n",
      "Done.\n",
      "Searching for \"I Like You (A Happier Song)\" by Post Malone Featuring Doja Cat...\n",
      "Done.\n",
      "Searching for \"You Proof\" by Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"Bad Habit\" by Steve Lacy...\n",
      "Done.\n",
      "Searching for \"Sunroof\" by Nicky Youre & dazy...\n",
      "Done.\n",
      "Searching for \"One Right Now\" by Post Malone & The Weeknd...\n",
      "Done.\n",
      "Searching for \"Good 4 U\" by Olivia Rodrigo...\n",
      "Done.\n",
      "Searching for \"Numb Little Bug\" by Em Beihold...\n",
      "Done.\n",
      "Searching for \"Jimmy Cooks\" by Drake Featuring 21 Savage...\n",
      "Done.\n",
      "Searching for \"'Til You Can't\" by Cody Johnson...\n",
      "Done.\n",
      "Searching for \"Fancy Like\" by Walker Hayes...\n",
      "Done.\n",
      "Searching for \"The Kind Of Love We Make\" by Luke Combs...\n",
      "Done.\n",
      "Searching for \"I Ain't Worried\" by OneRepublic...\n",
      "Done.\n",
      "Searching for \"Break My Soul\" by Beyonce...\n",
      "Done.\n",
      "Searching for \"Something In The Orange\" by Zach Bryan...\n",
      "Done.\n",
      "Searching for \"Save Your Tears\" by The Weeknd & Ariana Grande...\n",
      "Done.\n",
      "Searching for \"Smokin Out The Window\" by Silk Sonic (Bruno Mars & Anderson .Paak)...\n",
      "Done.\n",
      "Searching for \"Levitating\" by Dua Lipa...\n",
      "Done.\n",
      "Searching for \"In A Minute\" by Lil Baby...\n",
      "Done.\n",
      "Searching for \"Moscow Mule\" by Bad Bunny...\n",
      "Done.\n",
      "Searching for \"You Right\" by Doja Cat & The Weeknd...\n",
      "Done.\n",
      "Searching for \"She Had Me At Heads Carolina\" by Cole Swindell...\n",
      "Done.\n",
      "Searching for \"Vegas\" by Doja Cat...\n",
      "Done.\n",
      "Searching for \"Pushin P\" by Gunna & Future Featuring Young Thug...\n",
      "Done.\n",
      "Searching for \"Buy Dirt\" by Jordan Davis Featuring Luke Bryan...\n",
      "Done.\n",
      "Searching for \"I Hate U\" by SZA...\n",
      "Done.\n",
      "Searching for \"Boyfriend\" by Dove Cameron...\n",
      "Done.\n",
      "Searching for \"Glimpse Of Us\" by Joji...\n",
      "Done.\n",
      "Searching for \"Surface Pressure\" by Jessica Darrow...\n",
      "Done.\n",
      "Searching for \"Fall In Love\" by Bailey Zimmerman...\n",
      "Done.\n",
      "Searching for \"Love Nwantiti (Ah Ah Ah)\" by CKay...\n",
      "Done.\n",
      "Searching for \"Super Freaky Girl\" by Nicki Minaj...\n",
      "Done.\n",
      "Searching for \"Hrs And Hrs\" by Muni Long...\n",
      "Done.\n",
      "Searching for \"Sand In My Boots\" by Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"MAMIII\" by Becky G X Karol G...\n",
      "Done.\n",
      "Searching for \"Knife Talk\" by Drake Featuring 21 Savage & Project Pat...\n",
      "Done.\n",
      "Searching for \"AA\" by Walker Hayes...\n",
      "Done.\n",
      "Searching for \"Sweetest Pie\" by Megan Thee Stallion & Dua Lipa...\n",
      "Done.\n",
      "Searching for \"Provenza\" by Karol G...\n",
      "Done.\n",
      "Searching for \"Essence\" by Wizkid Featuring Justin Bieber & Tems...\n",
      "Done.\n",
      "Searching for \"All I Want For Christmas Is You\" by Mariah Carey...\n",
      "Done.\n",
      "Searching for \"Bam Bam\" by Camila Cabello Featuring Ed Sheeran...\n",
      "Done.\n",
      "Searching for \"5 Foot 9\" by Tyler Hubbard...\n",
      "Done.\n",
      "Searching for \"Get Into It (Yuh)\" by Doja Cat...\n",
      "Done.\n",
      "Searching for \"Efecto\" by Bad Bunny...\n",
      "Done.\n",
      "Searching for \"Rock And A Hard Place\" by Bailey Zimmerman...\n",
      "Done.\n",
      "Searching for \"Doin' This\" by Luke Combs...\n",
      "Done.\n",
      "Searching for \"Oh My God\" by Adele...\n",
      "Done.\n",
      "Searching for \"Better Days\" by NEIKED X Mae Muller X Polo G...\n",
      "Done.\n",
      "Searching for \"Meet Me At Our Spot\" by THE ANXIETY: WILLOW & Tyler Cole...\n",
      "Done.\n",
      "Searching for \"Fingers Crossed\" by Lauren Spencer-Smith...\n",
      "Done.\n",
      "Searching for \"All Too Well (Taylor's Version)\" by Taylor Swift...\n",
      "Done.\n",
      "Searching for \"Party\" by Bad Bunny & Rauw Alejandro...\n",
      "Done.\n",
      "Searching for \"Despues de La Playa\" by Bad Bunny...\n",
      "Done.\n",
      "Searching for \"You Should Probably Leave\" by Chris Stapleton...\n",
      "Done.\n",
      "Searching for \"Rockin' Around The Christmas Tree\" by Brenda Lee...\n",
      "Done.\n",
      "Searching for \"Broadway Girls\" by Lil Durk Featuring Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"Take My Name\" by Parmalee...\n",
      "Done.\n",
      "Searching for \"What Happened To Virgil\" by Lil Durk Featuring Gunna...\n",
      "Done.\n",
      "Searching for \"Puffin On Zootiez\" by Future...\n",
      "Done.\n",
      "Searching for \"Like I Love Country Music\" by Kane Brown...\n",
      "Done.\n",
      "Searching for \"Jingle Bell Rock\" by Bobby Helms...\n",
      "Done.\n",
      "Searching for \"Ojitos Lindos\" by Bad Bunny & Bomba Estereo...\n",
      "Done.\n",
      "Searching for \"Trouble With A Heartbreak\" by Jason Aldean...\n",
      "Done.\n",
      "Searching for \"A Holly Jolly Christmas\" by Burl Ives...\n",
      "Done.\n",
      "Searching for \"Kiss Me More\" by Doja Cat Featuring SZA...\n",
      "Done.\n",
      "Searching for \"She Likes It\" by Russell Dickerson & Jake Scott...\n",
      "Done.\n",
      "Searching for \"Never Say Never\" by Cole Swindell / Lainey Wilson...\n",
      "Done.\n",
      "Searching for \"Damn Strait\" by Scotty McCreery...\n",
      "Done.\n",
      "Searching for \"She's All I Wanna Be\" by Tate McRae...\n",
      "Done.\n",
      "Searching for \"Last Night Lonely\" by Jon Pardi...\n",
      "Done.\n",
      "Searching for \"Flower Shops\" by ERNEST Featuring Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"To The Moon!\" by JNR CHOI & Sam Tompkins...\n",
      "Done.\n",
      "Searching for \"Unholy\" by Sam Smith & Kim Petras...\n",
      "Done.\n",
      "Searching for \"One Mississippi\" by Kane Brown...\n",
      "Done.\n",
      "Searching for \"Circles Around This Town\" by Maren Morris...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "store_lyrics(year = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from a playlist from spotify 不要重新运行\n",
    "### How to find playlist ID:\n",
    "![playlist id](imgs/playlist_id.png)\n",
    "\n",
    "Or if you share the playlist with link, find the string before `?si=`:  \n",
    "https://open.spotify.com/playlist/**37i9dQZF1DX5Ejj0EkURtP**?si=a1e0243dd67c4cc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Apocalypse\" by Cigarettes After Sex...\n",
      "Done.\n",
      "Searching for \"Sunsetz\" by Cigarettes After Sex...\n",
      "Done.\n",
      "Searching for \"Cry\" by Cigarettes After Sex...\n",
      "Done.\n",
      "Searching for \"K.\" by Cigarettes After Sex...\n",
      "Done.\n",
      "Searching for \"My Jinji\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"I Know You Know I Love You\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"Jellyfish\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"我是一隻魚 I'm a Fish\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"Blues\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"Welcome To\" by Sunset Rollercoaster...\n",
      "Specified song does not contain lyrics. Rejecting.\n",
      "There's error when getting lyrcis of 'Welcome To' by Sunset Rollercoaster\n",
      "'NoneType' object has no attribute 'lyrics'\n",
      "Searching for \"Vanilla\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"Villa\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"I Wanna Be Yours\" by Arctic Monkeys...\n",
      "Done.\n",
      "Searching for \"I Wanna Be Adored - Remastered\" by The Stone Roses...\n",
      "No results found for: 'I Wanna Be Adored - Remastered The Stone Roses'\n",
      "There's error when getting lyrcis of 'I Wanna Be Adored - Remastered' by The Stone Roses\n",
      "'NoneType' object has no attribute 'lyrics'\n",
      "Searching for \"Sweet\" by Cigarettes After Sex...\n",
      "Done.\n",
      "Searching for \"Each Time You Fall in Love\" by Cigarettes After Sex...\n",
      "Done.\n",
      "Searching for \"You Might Be Sleeping\" by Jakob...\n",
      "Done.\n",
      "Searching for \"Candlelight\" by Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"有暖氣(You Nuan Chi)\" by Orange Ocean...\n",
      "Done.\n",
      "Searching for \"SLOW DANCING IN THE DARK\" by Joji...\n",
      "Done.\n",
      "Searching for \"海浪\" by deca joins...\n",
      "Done.\n",
      "Searching for \"Let There Be Light Again\" by 落日飛車 Sunset Rollercoaster...\n",
      "Done.\n",
      "Searching for \"Last Summer Whisper\" by Anri...\n",
      "Done.\n",
      "Searching for \"Perfect Sense\" by Arctic Monkeys...\n",
      "Done.\n",
      "Searching for \"J'aime pas le goût - A COLORS SHOW\" by LYNN...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "store_lyrics(playlist_id=\"1q2ztYCQCBrq14wFEJKOB8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '2022'\n",
    "lyrics_token = read_cleaned_data(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['come', 'on', 'harry', 'we', 'want', 'to', 'say', 'goodnight', 'to', 'you'], ['holding', 'me', 'back'], ['gravity', 'holding', 'me', 'back'], ['i', 'want', 'you', 'to', 'hold', 'out', 'palm', 'of', 'your', 'hand'], ['why', 'do', 'not', 'we', 'leave', 'it', 'at', 'that'], ['nothing', 'to', 'say'], ['when', 'everything', 'gets', 'in', 'way'], ['seems', 'you', 'can', 'not', 'be', 'replaced'], ['and', 'i', 'am', 'one', 'who', 'will', 'stay', 'oh-oh-oh'], ['in', 'this', 'world', 'it', 'just', 'us'], ['you', 'know', 'it', 'not', 'same', 'as', 'it', 'was'], ['in', 'this', 'world', 'it', 'just', 'us'], ['you', 'know', 'it', 'not', 'same', 'as', 'it', 'was'], ['as', 'it', 'was', 'as', 'it', 'was'], ['you', 'know', 'it', 'not', 'same'], ['answer', 'phone'], ['``', 'harry', 'you', 'are', 'no', 'good', 'alone'], ['why', 'are', 'you', 'sitting', 'at', 'home', 'on', 'floor'], ['what', 'kind', 'of', 'pills', 'are', 'you', 'on', '``'], ['ringing', 'bell'], ['and', 'nobody', 'coming', 'to', 'help'], ['your', 'daddy', 'lives', 'by', 'himself'], ['he', 'just', 'wants', 'to', 'know', 'that', 'you', 'are', 'well', 'oh-oh-oh'], ['you', 'might', 'also', 'like'], ['in', 'this', 'world', 'it', 'just', 'us'], ['you', 'know', 'it', 'not', 'same', 'as', 'it', 'was'], ['in', 'this', 'world', 'it', 'just', 'us'], ['you', 'know', 'it', 'not', 'same', 'as', 'it', 'was'], ['as', 'it', 'was', 'as', 'it', 'was'], ['you', 'know', 'it', 'not', 'same'], ['go', 'home', 'get', 'ahead', 'light-speed', 'internet'], ['i', 'do', 'not', 'want', 'to', 'talk', 'about', 'way', 'that', 'it', 'was'], ['leave', 'america', 'two', 'kids', 'follow', 'her'], ['i', 'do', 'not', 'want', 'to', 'talk', 'about', 'who', 'doing', 'it', 'first'], ['hey'], ['as', 'it', 'was'], ['you', 'know', 'it', 'not', 'same', 'as', 'it', 'was'], ['as', 'it', 'was', 'as', 'it', 'was', 'embed']]\n",
      "---------------\n",
      "dict_keys(['01_Heat Waves', '02_As It Was', '03_Stay', '04_Easy On Me', '05_Shivers', '06_First Class', '07_Big Energy', '08_Ghost', '09_Super Gremlin', '100_Circles Around This Town', '10_Cold Heart PNAU Remix', '11_Wait For U', '12_About Damn Time', '13_Bad Habits', '14_Thats What I Want', '15_Enemy', '16_Industry Baby', '17_abcdefu', '18_Need To Know', '19_Wasted On You', '20_Me Porto Bonito', '21_Woman', '22_Titi Me Pregunto', '23_Running Up That Hill A Deal With God', '24_We Dont Talk About Bruno', '25_Late Night Talking', '26_I Like You A Happier Song', '27_You Proof', '28_Bad Habit', '29_Sunroof', '30_One Right Now', '31_Good 4 U', '32_Numb Little Bug', '33_Jimmy Cooks', '34_Til You Cant', '35_Fancy Like', '36_The Kind Of Love We Make', '37_I Aint Worried', '38_Break My Soul', '39_Something In The Orange', '40_Save Your Tears', '41_Smokin Out The Window', '42_Levitating', '43_In A Minute', '44_Moscow Mule', '45_You Right', '46_She Had Me At Heads Carolina', '47_Vegas', '48_Pushin P', '49_Buy Dirt', '50_I Hate U', '51_Boyfriend', '52_Glimpse Of Us', '53_Surface Pressure', '54_Fall In Love', '55_Love Nwantiti Ah Ah Ah', '56_Super Freaky Girl', '57_Hrs And Hrs', '58_Sand In My Boots', '59_MAMIII', '60_Knife Talk', '61_AA', '62_Sweetest Pie', '63_Provenza', '64_Essence', '65_All I Want For Christmas Is You', '66_Bam Bam', '67_5 Foot 9', '68_Get Into It Yuh', '69_Efecto', '70_Rock And A Hard Place', '71_Doin This', '72_Oh My God', '73_Better Days', '74_Meet Me At Our Spot', '75_Fingers Crossed', '76_All Too Well Taylors Version', '77_Party', '78_Despues de La Playa', '79_You Should Probably Leave', '80_Rockin Around The Christmas Tree', '81_Broadway Girls', '82_Take My Name', '83_What Happened To Virgil', '84_Puffin On Zootiez', '85_Like I Love Country Music', '86_Jingle Bell Rock', '87_Ojitos Lindos', '88_Trouble With A Heartbreak', '89_A Holly Jolly Christmas', '90_Kiss Me More', '91_She Likes It', '92_Never Say Never', '93_Damn Strait', '94_Shes All I Wanna Be', '95_Last Night Lonely', '96_Flower Shops', '97_To The Moon', '98_Unholy', '99_One Mississippi'])\n"
     ]
    }
   ],
   "source": [
    "print(lyrics_token[\"02_As It Was\"])\n",
    "print('---------------')\n",
    "print(lyrics_token.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow expects an array of unicode tokens on input, not a single string",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m topic_words \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      2\u001B[0m         [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcomputer\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minterface\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      3\u001B[0m         [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgraph\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminors\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrees\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      4\u001B[0m         ]\n\u001B[1;32m----> 6\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlyrics_token\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\isay\\workplace\\DACS-Elevator-Radio-Producer\\data\\base.py:149\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(topic_words, tokens)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcorpora\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcorpora\u001B[39;00m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcoherencemodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CoherenceModel\n\u001B[1;32m--> 149\u001B[0m dictionary \u001B[38;5;241m=\u001B[39m \u001B[43mcorpora\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDictionary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m corpus \u001B[38;5;241m=\u001B[39m [dictionary\u001B[38;5;241m.\u001B[39mdoc2bow(token) \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m tokens]\n\u001B[0;32m    152\u001B[0m cm \u001B[38;5;241m=\u001B[39m CoherenceModel(topics\u001B[38;5;241m=\u001B[39mtopic_words,\n\u001B[0;32m    153\u001B[0m                     texts\u001B[38;5;241m=\u001B[39mtokens,\n\u001B[0;32m    154\u001B[0m                     corpus\u001B[38;5;241m=\u001B[39mcorpus,\n\u001B[0;32m    155\u001B[0m                     dictionary\u001B[38;5;241m=\u001B[39mdictionary,\n\u001B[0;32m    156\u001B[0m                     coherence\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc_v\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\isay\\DACS-Elevator-Radio-Producer\\lib\\site-packages\\gensim\\corpora\\dictionary.py:78\u001B[0m, in \u001B[0;36mDictionary.__init__\u001B[1;34m(self, documents, prune_at)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_nnz \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m documents \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprune_at\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprune_at\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_lifecycle_event(\n\u001B[0;32m     80\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreated\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     81\u001B[0m         msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbuilt \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_docs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m documents (total \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_pos\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m corpus positions)\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     82\u001B[0m     )\n",
      "File \u001B[1;32mD:\\isay\\DACS-Elevator-Radio-Producer\\lib\\site-packages\\gensim\\corpora\\dictionary.py:204\u001B[0m, in \u001B[0;36mDictionary.add_documents\u001B[1;34m(self, documents, prune_at)\u001B[0m\n\u001B[0;32m    201\u001B[0m         logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madding document #\u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, docno, \u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;66;03m# update Dictionary with the document\u001B[39;00m\n\u001B[1;32m--> 204\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdoc2bow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocument\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_update\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# ignore the result, here we only care about updating token ids\u001B[39;00m\n\u001B[0;32m    206\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbuilt \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m from \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m documents (total \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m corpus positions)\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_docs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_pos)\n",
      "File \u001B[1;32mD:\\isay\\DACS-Elevator-Radio-Producer\\lib\\site-packages\\gensim\\corpora\\dictionary.py:241\u001B[0m, in \u001B[0;36mDictionary.doc2bow\u001B[1;34m(self, document, allow_update, return_missing)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Convert `document` into the bag-of-words (BoW) format = list of `(token_id, token_count)` tuples.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    238\u001B[0m \n\u001B[0;32m    239\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(document, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoc2bow expects an array of unicode tokens on input, not a single string\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;66;03m# Construct (word, frequency) mapping.\u001B[39;00m\n\u001B[0;32m    244\u001B[0m counter \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mint\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: doc2bow expects an array of unicode tokens on input, not a single string"
     ]
    }
   ],
   "source": [
    "topic_words = [\n",
    "        ['human', 'computer', 'system', 'interface'],\n",
    "        ['graph', 'minors', 'trees', 'eps']\n",
    "        ]\n",
    "\n",
    "evaluate(topic_words, lyrics_token)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
