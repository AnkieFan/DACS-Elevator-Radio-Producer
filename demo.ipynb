{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DACS Elevator Radio Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new conda virtual environment\n",
    "#!conda create -n nlp_project7 python=3.9\n",
    "#!conda activate nlp_project7\n",
    "\n",
    "# Install all relied libraries\n",
    "#!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get data from billboard top 100\n",
    "If this year's data is stored then it won't grab again. You can directly use them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change this to start our journey:\n",
    "address = '2019'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.base import store_lyrics\n",
    "\n",
    "store_lyrics(year = address)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get data from a playlist from spotify\n",
    "### How to find playlist ID:\n",
    "![playlist id](imgs/playlist_id.png)\n",
    "\n",
    "Or if you share the playlist with link, find the string before `?si=`:  \n",
    "https://open.spotify.com/playlist/**37i9dQZF1DX5Ejj0EkURtP**?si=a1e0243dd67c4cc3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change this to start our journey:\n",
    "address = '4E4kp49bDhaSjyGFOyMKuz'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.base import store_lyrics\n",
    "\n",
    "store_lyrics(playlist_id=address)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.base import read_cleaned_data\n",
    "\n",
    "#address = \"2019\"\n",
    "lyrics_tokens = read_cleaned_data(address,remove_stopwords = True, stem_words = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = list(lyrics_tokens.keys())[15]\n",
    "print(name)\n",
    "print(lyrics_tokens[name])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get topics:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model.base import get_keywords\n",
    "\n",
    "result = get_keywords(lyrics_tokens)\n",
    "#result = get_keywords(lyrics_tokens, model = 'bert', n_gram=(1,1), word_no=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Store the extraction result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.base import store_extraction_result\n",
    "\n",
    "df = store_extraction_result(result, f\"{address}.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cluster and visualizaton\n",
    "### First: We choose the first keyword for every song and visualize them. So we have 100 keywords for 100 songs.    \n",
    "The size of circle is the frequency of the word appear in 100 keywords.  \n",
    "\n",
    "### Use lyrics as training data to train the word2vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train our own word2vec\n",
    "train_data = []\n",
    "for a in range(2018,2023):\n",
    "    l = read_cleaned_data(a,stem_words = False)\n",
    "    train_data.extend(sum(list(l.values()), []))\n",
    "\n",
    "print(train_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import w2v\n",
    "\n",
    "model = w2v.train_wvmodel(train_data)\n",
    "w2v.save_wvmodel(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"result/our_model.model\").wv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use pre-trained word2vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import cluster\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"./result/{address}.csv\")\n",
    "cluster.plot_one_per_song(df)\n",
    "#cluster.plot_one_per_song(df,cluster_no=8, wv_model = model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another way:  \n",
    "We choose the first 5 keywords for every song and sort them by frequency. So we have 500 keywords for 100 songs and we visualize the first 100 in the plot.    \n",
    "The size of circle is the frequency of the word appear in 100 keywords."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster.plot_five_per_song(df, cluster_no=8)\n",
    "#cluster.plot_five_per_song(df,cluster_no=8, wv_model = model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Other visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data import analysis\n",
    "from model import cluster\n",
    "\n",
    "words = cluster.generate_word_list(pd.read_csv(f\"./result/{address}.csv\"), 5)\n",
    "analysis.plot_word_cloud(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evaluation.title_compare import get_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"result/experiments/bert_ff.csv\")\n",
    "get_score(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.base import read_cleaned_data\n",
    "from evaluation.cv_umass import evaluate\n",
    "import pandas as pd\n",
    "\n",
    "address = 2018\n",
    "\n",
    "# u_mass test with our corpus\n",
    "model_df = pd.read_csv(f\"./result/experiments/tfidf_ff.csv\")\n",
    "\n",
    "lyrics_tokens = read_cleaned_data(address,remove_stopwords = False, stem_words = False)\n",
    "\n",
    "print(evaluate(model_df,lyrics_tokens))\n",
    "# evaluate(model_df,lyrics_tokens,method='umass')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}